{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "from keras.callbacks import History \n",
    "\n",
    "from keras import optimizers\n",
    "from keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di esempi nel train set: 25000\n",
      "Numero di esempi nel test set: 25000\n"
     ]
    }
   ],
   "source": [
    "# Split dataset into train and test set\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=5000)\n",
    "\n",
    "print(\"Numero di esempi nel train set: %d\" % len(X_train))\n",
    "print(\"Numero di esempi nel test set: %d\" % len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coding of sentences \n",
    "def onehot_encoding(data, size):\n",
    "    onehot = np.zeros((len(data), size))\n",
    "    for i, d in enumerate(data):\n",
    "        onehot[i,d] = 1.\n",
    "    return onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 5000)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_oh = onehot_encoding(X_train, 5000)\n",
    "X_test_oh = onehot_encoding(X_test, 5000)\n",
    "\n",
    "X_train_oh.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation of the model\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(5000,)))\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adamax', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "49/49 [==============================] - 79s 2s/step - loss: 0.4295 - accuracy: 0.8201\n",
      "Epoch 2/10\n",
      "49/49 [==============================] - 113s 2s/step - loss: 0.2320 - accuracy: 0.9100\n",
      "Epoch 3/10\n",
      "49/49 [==============================] - 87s 2s/step - loss: 0.1847 - accuracy: 0.9322\n",
      "Epoch 4/10\n",
      "49/49 [==============================] - 79s 2s/step - loss: 0.1508 - accuracy: 0.9467\n",
      "Epoch 5/10\n",
      "49/49 [==============================] - 84s 2s/step - loss: 0.1161 - accuracy: 0.9618\n",
      "Epoch 6/10\n",
      "49/49 [==============================] - 81s 2s/step - loss: 0.0773 - accuracy: 0.9799\n",
      "Epoch 7/10\n",
      "49/49 [==============================] - 85s 2s/step - loss: 0.0458 - accuracy: 0.9919\n",
      "Epoch 8/10\n",
      "49/49 [==============================] - 77s 2s/step - loss: 0.0255 - accuracy: 0.9970\n",
      "Epoch 9/10\n",
      "49/49 [==============================] - 82s 2s/step - loss: 0.0158 - accuracy: 0.9984\n",
      "Epoch 10/10\n",
      "49/49 [==============================] - 82s 2s/step - loss: 0.0111 - accuracy: 0.9989\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1335b7fc430>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_oh, y_train, epochs=10, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation of dropout and  regularization l2 for overfitting\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import dropout\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(5000,), kernel_regularizer=l2(0.1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128,activation='relu', kernel_regularizer=l2(0.01)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(32,activation='relu',kernel_regularizer=l2(0.001)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(8,activation='relu', kernel_regularizer=l2(0.01)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adamax', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
      "1646592/1641221 [==============================] - 2s 1us/step\n"
     ]
    }
   ],
   "source": [
    "# Classification of a movie review from the internet\n",
    "word_index = imdb.get_word_index()\n",
    "\n",
    "review = \"what a waste of time and cash.. the movie was pointless. with no flow. no questions answered. just a waste. I never review movies but had to share how bad this was..compared to part 1- 2- and 3.... i don't know what else to say other than how misleading the commercial is.. the commercial was cut and spliced with video and audio that didn't even match what happened in the movie... you have been warned. when the movie was over.. people actually Boo'd. hopefully people will spread the word, and save others from throwing their money away. i know die-hard fans will go and give it a shot, but will be disappointed as well. Sinister was better and actually made you jump quite a few times.\"\n",
    "from re import sub\n",
    "\n",
    "def preprocess(review):\n",
    "    \n",
    "    # Removing any punctuation\n",
    "    review = sub(r'[^\\w\\s]','',review) \n",
    "    # Lowercase conversion\n",
    "    review = review.lower()\n",
    "    # Creating an array of words\n",
    "    review = review.split(\" \")\n",
    "\n",
    "    # Insering the ID\n",
    "    review_array = []\n",
    "\n",
    "    # Iterating through the words of the review\n",
    "    for word in review:\n",
    "        # we continue if the word is inside\n",
    "        # of the word list of the training corpus\n",
    "        if word in word_index:\n",
    "            # we extract the index of the word\n",
    "            index = word_index[word] \n",
    "            # We continue if the index is less than or equal to 5000\n",
    "            # that is the number of words used for training\n",
    "            if index <= 5000:\n",
    "                # adding the ID to the array\n",
    "                review_array.append(word_index[word]+3)\n",
    "                \n",
    "    # Performing the one hot encoding on the list of indices\n",
    "    review_array = onehot_encoding([review_array],5000)\n",
    "    \n",
    "    return review_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REVIEW: what a waste of time and cash.. the movie was pointless. with no flow. no questions answered. just a waste. I never review movies but had to share how bad this was..compared to part 1- 2- and 3.... i don't know what else to say other than how misleading the commercial is.. the commercial was cut and spliced with video and audio that didn't even match what happened in the movie... you have been warned. when the movie was over.. people actually Boo'd. hopefully people will spread the word, and save others from throwing their money away. i know die-hard fans will go and give it a shot, but will be disappointed as well. Sinister was better and actually made you jump quite a few times.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Prediction\n",
    "x = preprocess(review)\n",
    "y = model.predict(x)[0]\n",
    "print(\"REVIEW: %s\" % review)\n",
    "print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00083727], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
